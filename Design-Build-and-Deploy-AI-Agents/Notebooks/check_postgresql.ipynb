{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bad74d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Tables and their schema:\n",
      "\n",
      "üîπ Table: checkpoint_migrations\n",
      "   - v: integer\n",
      "   üìä Row count: 10\n",
      "\n",
      "üîπ Table: checkpoints\n",
      "   - checkpoint: jsonb\n",
      "   - metadata: jsonb\n",
      "   - checkpoint_id: text\n",
      "   - thread_id: text\n",
      "   - type: text\n",
      "   - parent_checkpoint_id: text\n",
      "   - checkpoint_ns: text\n",
      "   üìä Row count: 9\n",
      "\n",
      "üîπ Table: checkpoint_blobs\n",
      "   - blob: bytea\n",
      "   - thread_id: text\n",
      "   - checkpoint_ns: text\n",
      "   - channel: text\n",
      "   - version: text\n",
      "   - type: text\n",
      "   üìä Row count: 18\n",
      "\n",
      "üîπ Table: checkpoint_writes\n",
      "   - blob: bytea\n",
      "   - idx: integer\n",
      "   - checkpoint_id: text\n",
      "   - task_id: text\n",
      "   - channel: text\n",
      "   - type: text\n",
      "   - thread_id: text\n",
      "   - task_path: text\n",
      "   - checkpoint_ns: text\n",
      "   üìä Row count: 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import psycopg\n",
    "\n",
    "DB_URI = \"postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable\"\n",
    "\n",
    "with psycopg.connect(DB_URI) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        # Step 1: List all table names in the 'public' schema\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT table_name\n",
    "            FROM information_schema.tables\n",
    "            WHERE table_schema = 'public' AND table_type = 'BASE TABLE';\n",
    "        \"\"\")\n",
    "        tables = cur.fetchall()\n",
    "\n",
    "        print(\"üì¶ Tables and their schema:\\n\")\n",
    "\n",
    "        for (table_name,) in tables:\n",
    "            print(f\"üîπ Table: {table_name}\")\n",
    "\n",
    "            # Step 2: Get columns and types\n",
    "            cur.execute(f\"\"\"\n",
    "                SELECT column_name, data_type\n",
    "                FROM information_schema.columns\n",
    "                WHERE table_name = %s;\n",
    "            \"\"\", (table_name,))\n",
    "            columns = cur.fetchall()\n",
    "            for col in columns:\n",
    "                print(f\"   - {col[0]}: {col[1]}\")\n",
    "\n",
    "            # Step 3: Count rows in the table\n",
    "            cur.execute(f\"SELECT COUNT(*) FROM {table_name};\")\n",
    "            row_count = cur.fetchone()[0]\n",
    "            print(f\"   üìä Row count: {row_count}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbc2c80",
   "metadata": {},
   "source": [
    "## üß† Explanation of Each Table\n",
    "\n",
    "These tables are created by LangGraph's PostgresSaver checkpointing system to persist execution state.\n",
    "\n",
    "### üîπ `checkpoint_migrations`\n",
    "\n",
    "* **Purpose**: Internal versioning table used by LangGraph to track schema upgrades for checkpoints.\n",
    "* **Column:**\n",
    "\n",
    "  * `v`: An integer version number (like migrations in Django or Alembic).\n",
    "* **Row count**: One per migration applied. You can ignore this unless debugging LangGraph internals.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ `checkpoints`\n",
    "\n",
    "* **Purpose**: Stores **graph state** (nodes, memory, etc.) at various execution points.\n",
    "* **Columns:**\n",
    "\n",
    "  * `checkpoint` and `metadata`: `jsonb` objects with full serialized state and config.\n",
    "  * `checkpoint_id`: Unique ID for this checkpoint.\n",
    "  * `thread_id`: Which \"chat thread\" or agent run this belongs to.\n",
    "  * `type`, `parent_checkpoint_id`, `checkpoint_ns`: Internal categorization for how checkpoints are grouped and restored.\n",
    "\n",
    "This is the most useful table if you're trying to **resume, inspect, or debug agent runs**.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ `checkpoint_blobs`\n",
    "\n",
    "* **Purpose**: Stores binary blobs for graph communication (e.g. passing channel state between nodes).\n",
    "* **Columns**: `blob` is binary data (serialized Python objects); others describe which graph and channel it belongs to.\n",
    "* **Most of the time**, you don‚Äôt need this directly unless you‚Äôre reconstructing or replaying executions.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ `checkpoint_writes`\n",
    "\n",
    "* **Purpose**: Detailed log of what was written to each channel at each checkpoint.\n",
    "* Useful for debugging communication between graph nodes.\n",
    "* Includes info like `task_id`, `channel`, `type`, `task_path`.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52752e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Table: checkpoint_migrations\n",
      "|   v |\n",
      "|-----|\n",
      "|   0 |\n",
      "|   1 |\n",
      "|   2 |\n",
      "|   3 |\n",
      "|   4 |\n",
      "|   5 |\n",
      "|   6 |\n",
      "|   7 |\n",
      "|   8 |\n",
      "|   9 |\n",
      "\n",
      "üîπ Table: checkpoints\n",
      "| thread_id   | checkpoint_ns   | checkpoint_id   | parent_checkpoint_id   | type   | checkpoint   | metadata   |\n",
      "|-------------|-----------------|-----------------|------------------------|--------|--------------|------------|\n",
      "\n",
      "üîπ Table: checkpoint_blobs\n",
      "| thread_id   | checkpoint_ns   | channel   | version   | type   | blob   |\n",
      "|-------------|-----------------|-----------|-----------|--------|--------|\n",
      "\n",
      "üîπ Table: checkpoint_writes\n",
      "| thread_id   | checkpoint_ns   | checkpoint_id   | task_id   | idx   | channel   | type   | blob   | task_path   |\n",
      "|-------------|-----------------|-----------------|-----------|-------|-----------|--------|--------|-------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\farza\\AppData\\Local\\Temp\\ipykernel_25964\\942727820.py:22: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(f\"SELECT * FROM {table_name};\", conn)\n",
      "C:\\Users\\farza\\AppData\\Local\\Temp\\ipykernel_25964\\942727820.py:22: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(f\"SELECT * FROM {table_name};\", conn)\n",
      "C:\\Users\\farza\\AppData\\Local\\Temp\\ipykernel_25964\\942727820.py:22: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(f\"SELECT * FROM {table_name};\", conn)\n"
     ]
    }
   ],
   "source": [
    "import psycopg\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "DB_URI = \"postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable\"\n",
    "\n",
    "with psycopg.connect(DB_URI) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        # Get all tables\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT table_name\n",
    "            FROM information_schema.tables\n",
    "            WHERE table_schema = 'public' AND table_type = 'BASE TABLE';\n",
    "        \"\"\")\n",
    "        tables = cur.fetchall()\n",
    "\n",
    "        for (table_name,) in tables:\n",
    "            print(f\"\\nüîπ Table: {table_name}\")\n",
    "\n",
    "            try:\n",
    "                # Load all rows into a DataFrame\n",
    "                df = pd.read_sql(f\"SELECT * FROM {table_name};\", conn)\n",
    "                # If binary columns, decode where possible\n",
    "                for col in df.columns:\n",
    "                    if df[col].dtype == 'object' and df[col].apply(lambda x: isinstance(x, memoryview)).any():\n",
    "                        df[col] = df[col].apply(lambda x: x.tobytes().decode('utf-8', errors='ignore') if isinstance(x, memoryview) else x)\n",
    "\n",
    "                # Pretty print as markdown-style table\n",
    "                print(df.to_markdown(index=False, tablefmt=\"github\"))\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error loading table {table_name}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
