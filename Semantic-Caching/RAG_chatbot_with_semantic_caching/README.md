# TaskFlow RAG Chatbot with Semantic Caching

A smart chatbot that combines semantic caching with RAG (Retrieval-Augmented Generation) to answer questions about TaskFlow. The system checks a cache first for instant responses, and only uses the full RAG pipeline when needed.

## ğŸ¯ What This Does

**Two-Tier Response System:**
1. **Cache Hit (âš¡ ~0.4s)**: If you've asked something similar before, get instant answer
2. **RAG Pipeline (ğŸ” ~4-10s)**: If question is new, search ChromaDB vectorstore and generate answer

**Smart Features:**
- Understands question variations ("What's the cost?" = "What are the pricing plans?")
- Learns from feedback (approve good answers to cache them)
- Auto-stops after 2 retry attempts if no answer found
- Shows visual indicators for cache hits vs RAG searches

## ğŸ“‹ Prerequisites

- Python 3.11+
- OpenAI API key
- ~5 minutes for setup

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Set Your OpenAI API Key

```bash
export OPENAI_API_KEY='your-api-key-here'
```

Or create a `.env` file:
```
OPENAI_API_KEY=your-api-key-here
```

### 3. Create the ChromaDB Vectorstore

**First time only** - creates persistent document database:

```bash
python prepare_data_chroma.py
```

Expected output:
```
âœ… ChromaDB vectorstore created successfully!
   Collection: taskflow_docs
   Total chunks: 150+
   Location: data/chroma_db
```

This creates a `data/chroma_db/` folder with embedded documents.

### 4. Run the Streamlit App

```bash
streamlit run streamlit_app.py
```

The app opens in your browser at `http://localhost:8501`

## ğŸ’¬ How to Use

### In the Streamlit App:

1. **Click "ğŸš€ Initialize Assistant"** in the sidebar
2. **Ask questions** like:
   - "How do I create a new project?" âš¡ (cache hit)
   - "What are the pricing plans?" âš¡ (cache hit)
   - "How do I set up automations?" ğŸ” (RAG search)

3. **Watch the response**:
   - **Green box**: Answer from cache (instant!)
   - **Yellow box**: Answer from RAG (searched documents)

4. **Give feedback** (for RAG answers only):
   - ğŸ‘ **Yes, add to cache** â†’ Future similar questions get instant answers
   - ğŸ‘ **No, don't cache** â†’ Answer won't be saved

### What You'll See:

**Cache Hit Example:**
```
âœ¨ Answer from Cache (Instant Response!)
Matched question: "How do I create a new project?"
Similarity Score: 98.5%
â±ï¸ Response time: 0.12s
```

**RAG Search Example:**
```
ğŸ” Answer from RAG Pipeline (Full Search)
This answer was generated by searching the documentation
â±ï¸ Response time: 4.32s

ğŸ’­ Was this answer helpful?
[ğŸ‘ Yes, add to cache] [ğŸ‘ No, don't cache]
```

## ğŸ“Š Understanding the System

### Cache Layer (Fast âš¡)
- **What**: In-memory semantic search of Q&A pairs
- **Speed**: ~0.4s
- **How**: Uses OpenAI embeddings to match similar questions
- **Data**: Starts with 8 seed pairs, grows with approved answers

### ChromaDB VectorStore (Document Storage)
- **What**: Persistent database of TaskFlow documentation
- **Content**: 30 FAQ entries + main docs = ~150 chunks
- **How**: Similarity search finds relevant documents
- **Location**: `data/chroma_db/`

### LangGraph RAG Pipeline (Smart Search ğŸ”)
- **When**: Triggered on cache miss
- **Steps**:
  1. Retrieve top-4 relevant documents from ChromaDB
  2. Grade relevance
  3. If not relevant: rewrite question and retry (max 2 times)
  4. If relevant: generate answer using context
  5. If still no answer: return helpful fallback message

### The Flow:
```
User Question
    â†“
Check Cache â†’ HIT? â†’ Return answer âš¡
    â†“ NO
Query ChromaDB
    â†“
LangGraph Pipeline
    â†“
Generate Answer ğŸ”
    â†“
User Feedback â†’ Approve? â†’ Add to Cache
```

## ğŸ“ Example Questions to Try

### Will Hit Cache (Instant âš¡):
```
âœ“ "How do I create a new project?"
âœ“ "What are the pricing plans?"
âœ“ "Can I integrate with Slack?"
âœ“ "How do I reset my password?"
```

### Will Use RAG (4-10s ğŸ”):
```
âœ“ "How do I set up automations?"
âœ“ "What's the difference between workspaces and projects?"
âœ“ "Can I customize task fields?"
âœ“ "How do I track time on tasks?"
```

### Test Semantic Matching:
Original: "What are the pricing plans?"
Matches:
- "What's the cost?" âœ“
- "How much does it cost?" âœ“
- "Tell me about pricing" âœ“

## âš™ï¸ Configuration

### Adjust Cache Similarity

**In Streamlit sidebar**: Use the "Cache Similarity Threshold" slider

**In code**:
```python
chatbot = CachedRAGChatbot(
    cache_distance_threshold=0.25,  # Stricter (fewer matches)
    cache_distance_threshold=0.35,  # Balanced (recommended)
    cache_distance_threshold=0.45,  # Looser (more matches)
)
```

### Adjust Maximum Retries

```python
chatbot = CachedRAGChatbot(
    max_rewrites=2  # Default (stops after 2 retry attempts)
)
```

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ cached_rag_chatbot_chroma.py    # Main chatbot logic
â”œâ”€â”€ document_store_chroma.py            # ChromaDB manager
â”œâ”€â”€ semantic_cache.py                   # Cache implementation
â”œâ”€â”€ streamlit_app.py                    # Interactive UI
â”œâ”€â”€ prepare_data_chroma.py              # Data setup script
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ chroma_db/                      # ChromaDB storage (created by setup)
â”‚   â”œâ”€â”€ taskflow_faq.csv                # 30 FAQ entries
â”‚   â”œâ”€â”€ taskflow_docs.txt               # Main documentation
â”‚   â””â”€â”€ taskflow_cache_seed.csv         # Initial cache (8 pairs)
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ langgraph_flow.png              # Graph visualization (auto-generated)
â”‚   â””â”€â”€ taskflow_cache_approved.csv     # User-approved cache additions
â”‚
â””â”€â”€ requirements.txt                    # Dependencies
```

## ğŸ“ˆ Monitoring Performance

**In the Streamlit sidebar**, you'll see real-time stats:

```
Session Statistics
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total Queries: 20
Cache Hits: 12 (60%)
Cache Misses: 8 (40%)
Approved: 5

Cache Size: 13 pairs
Hit Rate: 60%
```

**What this means:**
- 60% of questions answered instantly
- Cache growing with user feedback
- Performance improving over time

## ğŸ”§ Troubleshooting

### "OPENAI_API_KEY not found"
**Solution**: Set the environment variable or create a `.env` file

### "ChromaDB not found"
**Solution**: Run `python prepare_data_chroma.py` first

### Cache hit rate too low
**Solution**: Increase similarity threshold in sidebar (try 0.2)

### Too many false cache hits
**Solution**: Decrease similarity threshold (try 0.1)

### "Graph not initialized" error
**Solution**: Click "Initialize Assistant" button in Streamlit sidebar

## ğŸ¯ Key Features

- âœ… **Semantic Caching**: Similar questions get cached answers
- âœ… **Persistent ChromaDB**: Documents embedded once, used forever
- âœ… **Smart Retry Logic**: Auto-stops after 2 attempts if no answer found
- âœ… **User Feedback Loop**: Improve cache quality through approvals
- âœ… **Visual Indicators**: Clear cache hit/miss status
- âœ… **Error Handling**: Helpful messages when information isn't found
- âœ… **Graph Visualization**: Auto-saved diagram in `outputs/`

## ğŸ“Š Performance Comparison

| Scenario | Cache Hit | RAG Search |
|----------|-----------|------------|
| **Response Time** | ~0.4s | ~4-10s |
| **API Calls** | 1 (embedding only) | 4-6 (embedding + LLM) |
| **Cost** | ~$0.0001 | ~$0.01-0.02 |
| **Speedup** | **20x faster** | Baseline |

## ğŸ“ What You'll Learn

This project demonstrates:
1. **Semantic Caching** - Speed up responses with meaning-based matching
2. **RAG Architecture** - Retrieve relevant docs before generating answers
3. **LangGraph Workflows** - Orchestrate complex LLM interactions
4. **ChromaDB** - Persistent vector database for documents
5. **User Feedback Loops** - Improve system quality over time

## ğŸ’¡ Tips

1. **First run is slow** (~30-60s to create ChromaDB) - subsequent runs are fast
2. **Approve good answers** to build your cache
3. **Monitor hit rate** to gauge system performance
4. **Adjust threshold** based on your needs (precision vs recall)
5. **Check graph visualization** in `outputs/langgraph_flow.png`

## ğŸ†˜ Need Help?

1. **Check console logs** - Verbose mode shows detailed flow
2. **Run test script**: `python test_complete_flow.py`
3. **Review documentation**: See `IMPROVEMENTS_GUIDE.md` for technical details
4. **Check graph**: Look at `outputs/langgraph_flow.png` to understand flow

## ğŸ“ Credits

Built with:
- **LangChain & LangGraph** - RAG orchestration
- **ChromaDB** - Vector database
- **OpenAI** - Embeddings and language models
- **Streamlit** - Interactive UI

---

**Ready?** Run these three commands and you're set:

```bash
pip install -r requirements.txt
python prepare_data_chroma.py
streamlit run streamlit_app.py
```

Enjoy your smart caching RAG chatbot! ğŸ‰